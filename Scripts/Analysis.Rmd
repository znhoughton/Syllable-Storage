---
title: "Analysis"
author: "Zachary Houghton"
date: "2024-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(data.table)
library(phonics)
library(httr)
library(rvest)

```

## Preprocessing and Analysis

Some pre-processing:

```{r}
data = read_csv('../Data/Database_AllParticipants_syllable_storage_355928_2024-01-19_19h23.45_b9e68166-5665-4c6d-900b-d033900d1ab0.csv') 

data_analysis = data %>%
  mutate(resp = ifelse(!is.na(textbox.text), textbox.text, ifelse(!is.na(textbox_2.text), textbox_2.text, ifelse(!is.na(textbox_3.text), textbox_3.text, NA)))) %>%
  select(session, Phoneme1Surprisal, Phoneme2Surprisal, Phoneme3Surprisal, LexicalFrequency, Condition, NoiseLevel, `__participant`, Words, resp) %>%
  rename(participant = `__participant`) %>%
  rename(item = Words) %>%
  na.omit()

data_analysis$item = tolower(data_analysis$item)
#what do we need for the j-factor calculations? dictionary calculating, for each participant, the probability of each phoneme being incorrect (e.g., for the participant)

```

Next, let's convert both participants' responses, and our words/non-words to ARPABET:

```{r}
items = data_analysis$item
resps = data_analysis$resp

write.table(items, '../Data/items.txt', col.names = F, row.names = F)
write.table(resps, '../Data/responses.txt', col.names = F, row.names = F)

url = 'http://www.speech.cs.cmu.edu/cgi-bin/tools/logios/lextool2.pl'

form_data = list(
  wordfile = upload_file('../Data/items.txt')
)

response = POST(url, body = form_data)



result = content(response, as = 'text')
print(result)

parsed_html <- read_html(result)
comments <- html_nodes(parsed_html, xpath = "//comment()")

# Convert comments to a character vector
comment_text <- as.character(comments)

pattern <- "DICT\\s+(\\w+)"

dict_url = trimws(gsub("<!-- DICT (.*?) -->", "\\1", comment_text))
  
words = read.csv(url(dict_url), header = F) 
colnames(words) = 'item_arpabet'
words = words %>%
  separate(item_arpabet, into = c('item', 'item_arpabet'), sep = '^\\S*\\K')

form_data = list(
  wordfile = upload_file('../Data/responses.txt')
)

response = POST(url, body = form_data)



result = content(response, as = 'text')
print(result)

parsed_html <- read_html(result)
comments <- html_nodes(parsed_html, xpath = "//comment()")

# Convert comments to a character vector
comment_text <- as.character(comments)

pattern <- "DICT\\s+(\\w+)"

dict_url = trimws(gsub("<!-- DICT (.*?) -->", "\\1", comment_text))
  
responses = read.csv(url(dict_url), header = F) 
colnames(responses) = 'resp_arpabet'
responses = responses %>%
  separate(resp_arpabet, into = c('resp', 'resp_arpabet'), sep = '^\\S*\\K')

words$item = tolower(words$item)
responses$resp = tolower(responses$resp)

arpabet_symbols = cbind(words, responses) %>%
  select(-item, -resp)

data_analysis_test = cbind(data_analysis, arpabet_symbols)
  
```

```{r}
extract_letter_pairs <- function(word1, word2) {
  letters1 <- unlist(strsplit(as.character(word1), ""))
  letters2 <- unlist(strsplit(as.character(word2), ""))
  min_length <- min(length(letters1), length(letters2))
  pairs <- paste(letters1[1:min_length], letters2[1:min_length], sep = ",")
  return(pairs)
}

# Apply the function to the dataframe and create a new column
data_analysis$letter_pairs <- mapply(extract_letter_pairs, data_analysis$item, data_analysis$resp)

new_df <- data_analysis %>%
  unnest(letter_pairs) %>%
  mutate(letter = sapply(strsplit(letter_pairs, ","), `[`, 1)) %>%
  separate(letter_pairs, into = c('target_phoneme', 'response_phoneme'), sep = ',') %>%
  mutate(correct = ifelse(target_phoneme == response_phoneme, 1, 0)) %>%
  group_by(participant, letter) %>%
  summarize(total = n(), total_correct = sum(correct), perc = total_correct/total)


data_analysis = data_analysis %>%
  mutate(first_letter = substr(item, 1, 1)) %>%
  mutate(second_letter = substr(item, 2, 2)) %>%
  mutate(third_letter = substr(item, 3, 3)) %>%
  left_join(new_df, by = c('first_letter' = 'letter', 'participant')) %>%
  rename_with(~ paste0(., "_letter1"), total:perc) %>%
  left_join(new_df, by = c('second_letter' = 'letter', 'participant')) %>%
  rename_with(~ paste0(., "_letter2"), total:perc) %>%
  left_join(new_df, by = c('third_letter' = 'letter', 'participant')) %>%
  rename_with(~ paste0(., "_letter3"), total:perc)

data_analysis = data_analysis %>%
  mutate(resp_word_correct = ifelse(item == resp, 1, 0)) %>%
  select(-letter_pairs)
```

If we want to preserver positional information we can do this:

```{r}
#not sure if we want to do this
```

<!--# to-do: change analysis to arpabet instead of orthography, for real words can access it from dictionary, for nonce words we already have arpabet, for human responses that'll be the tricky part. Maybe can make a key or something -->
